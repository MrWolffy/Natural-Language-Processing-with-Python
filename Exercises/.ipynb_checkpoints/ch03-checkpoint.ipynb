{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 23"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Are you able to write a regular expression to tokenize text in such a way that the word _don’t_ is tokenized into _do_ and _n’t_? Explain why this regular expression won’t work: `«n't|\\w+»`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['do', \"n't\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.regexp_tokenize('don\\'t', r'((?:\\w+(?=n\\'t))|n\\'t)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> _Pig Latin_ is a simple transformation of English text. Each word of the text is converted as follows: move any consonant (or consonant cluster) that appears at the start of the word to the end, then append _ay_, e.g., _string_ → _ingstray_, _idle_ → _idleay_ (see http://en.wikipedia.org/wiki/Pig_Latin).\n",
    ">\n",
    "> a. Write a function to convert a word to Pig Latin.\n",
    ">\n",
    "> b. Write code that converts text, instead of individual words.\n",
    ">\n",
    "> c. Extend it further to preserve capitalization, to keep `qu` together (so that `quiet` becomes `ietquay`, for example), and to detect when `y` is used as a consonant (e.g., `yellow`) versus a vowel (e.g., `style`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pig_latin(word):\n",
    "    import re\n",
    "    idx = re.search('[aeiou]', word)\n",
    "    if idx is not None:\n",
    "        ret = word[idx.span()[0]:] + word[0:idx.span()[0]] + 'ay'\n",
    "    else:\n",
    "        ret = word\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ingstray'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pig_latin('string')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_pig_latin_text(text):\n",
    "    return [to_pig_latin(word) for word in nltk.word_tokenize(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['eThay',\n",
       " 'ojectPray',\n",
       " 'utenbergGay',\n",
       " 'ookEBay',\n",
       " 'ofay',\n",
       " 'imeCray',\n",
       " 'anday',\n",
       " 'unishmentPay',\n",
       " ',',\n",
       " 'by',\n",
       " 'odorFyay',\n",
       " 'ostoevskyDay']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_pig_latin_text('The Project Gutenberg EBook of Crime and Punishment, by Fyodor Dostoevsky')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 29"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Readability measures are used to score the reading difficulty of a text, for the purposes of selecting texts of appropriate difficulty for language learners. Let us define $\\mu_w$ to be the average number of letters per word, and $\\mu_s$ to be the average number of words per sentence, in a given text. The Automated Readability Index (ARI) of the text is defined to be: 4.71 $\\mu_w$ + 0.5 $\\mu_s$ - 21.43. Compute the ARI score for various sections of the Brown Corpus, including section `f` (popular lore) and `j` (learned). Make use of the fact that `nltk.corpus.brown.words()` produces a sequence of words, whereas `nltk.corpus.brown.sents()` produces a sequence of sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_ARI():\n",
    "    words = nltk.corpus.brown.words(categories=['lore', 'learned'])\n",
    "    sents = nltk.corpus.brown.sents(categories=['lore', 'learned'])\n",
    "    w = sum([len(word) for word in words]) / len(words)\n",
    "    s = len(words) / len(sents)\n",
    "    return 4.71 * w + 0.5 * s - 21.43"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.290781451862358"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cal_ARI()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 38"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> An interesting challenge for tokenization is words that have been split across a linebreak. E.g., if _long-term_ is split, then we have the string `long-\\nterm`.\n",
    ">\n",
    "> a. Write a regular expression that identifies words that are hyphenated at a linebreak. The expression will need to include the `\\n` character.\n",
    ">\n",
    "> b. Use `re.sub()` to remove the `\\n` character from these words.\n",
    ">\n",
    "> c. How might you identify words that should not remain hyphenated once the newline is removed, e.g., `'encyclo-\\npedia'`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 10), match='long-\\nterm'>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "re.search(r'[-\\w]+\\n[-\\w]+', 'long-\\nterm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'long-term'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'([-\\w]+)\\n([-\\w]+)', r'\\1\\2', 'long-\\nterm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aiuio', 'eaiou', 'eouio', 'euoia', 'oauaio', 'uiieioa']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words = ['attribution', 'confabulation', 'elocution',\n",
    "         'sequoia', 'tenacious', 'unidirectional']\n",
    "vsequences = set([''.join(re.findall(r'[aeiou]', word)) for word in words])\n",
    "sorted(vsequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a', 'i', 'u', 'i', 'o']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.findall(r'[aeiou]', 'attribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
