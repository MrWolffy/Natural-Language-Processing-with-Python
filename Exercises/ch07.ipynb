{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Write a tag pattern to match noun phrases containing plural head nouns, e.g., `many/JJ researchers/NNS, two/CD weeks/NNS, both/DT new/JJ positions/NNS`. Try to do this by generalizing the tag pattern that handled singular noun phrases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "sentence = [('many', 'JJ'), ('researchers', 'NNS'), ('two', 'CD'), ('weeks', 'NNS'),\n",
    "           ('both', 'DT'), ('new', 'JJ'), ('position', 'NNS')]\n",
    "\n",
    "grammar = \"NP: {<DT>?<JJ>*(<NN>|<NNS>)}\"\n",
    "\n",
    "cp = nltk.RegexpParser(grammar)\n",
    "result = cp.parse(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(S\n",
      "  (NP many/JJ researchers/NNS)\n",
      "  two/CD\n",
      "  (NP weeks/NNS)\n",
      "  (NP both/DT new/JJ position/NNS))\n"
     ]
    }
   ],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Apply the n-gram and Brill tagging methods to IOB chunk tagging. Instead of assigning POS tags to words, here we will assign IOB tags to the POS tags. E.g., if the tag DT (determiner) often occurs at the start of a chunk, it will be tagged `B` (begin). Evaluate the performance of these chunking methods relative to the regular expression chunking methods covered in this chapter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import conll2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = conll2000.chunked_sents('test.txt', chunk_types=['NP'])\n",
    "train_sents = conll2000.chunked_sents('train.txt', chunk_types=['NP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_sents = [(pos, iob) for sent in test_sents for (word, pos, iob) in nltk.chunk.tree2conlltags(sent)]\n",
    "train_sents = [(pos, iob) for sent in train_sents for (word, pos, iob) in nltk.chunk.tree2conlltags(sent)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature(sents, i):\n",
    "    return {'pos': sents[i][0],\n",
    "           'iob-prev': sents[i-1][1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = nltk.NaiveBayesClassifier.train((get_feature(train_sents, i), word[1]) \n",
    "                                             for (i, word) in enumerate(train_sents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9524452793549613"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(classifier, [(get_feature(test_sents, i), word[1])\n",
    "                       for (i, word) in enumerate(test_sents)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
